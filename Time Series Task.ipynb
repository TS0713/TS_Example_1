{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "360d4ed7",
   "metadata": {},
   "source": [
    "## Loading all libraries, setting data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cef7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.time_series import *\n",
    "base_path = os.getcwd()\n",
    "data_path = glob(os.path.join(base_path,\"input\",\"*.xlsx\"))[0]\n",
    "print (data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c9e67f",
   "metadata": {},
   "source": [
    "# Loading Excel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54ba19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data = pd.ExcelFile(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd947b53",
   "metadata": {},
   "source": [
    "## Extracting train and test data from respective sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0c64f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data.sheet_names\n",
    "train_data = excel_data.parse(\"Training Dataset\")\n",
    "test_data = excel_data.parse(\"Test Dataset\")\n",
    "# Fields\n",
    "# 'ProductType', 'Manufacturer', 'Area Code', 'Sourcing Channel','Product Size',\n",
    "# 'Product Type', 'Month of Sourcing', 'Sourcing Cost'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4031ec26",
   "metadata": {},
   "source": [
    "## Preparing the label by combining all the ABCDE columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd699d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"feature_category\"] = train_data['ProductType']+\"_\"+train_data['Manufacturer']+\"_\"+train_data['Area Code']+\"_\"+train_data['Sourcing Channel']+\"_\"+train_data['Product Size']+\"_\"+train_data['Product Type']\n",
    "train_feature_category = train_data[\"feature_category\"].unique().tolist()\n",
    "train_data[\"Date\"] = pd.to_datetime(train_data[\"Month of Sourcing\"])\n",
    "\n",
    "test_data[\"feature_category\"] = test_data['ProductType']+\"_\"+test_data['Manufacturer']+\"_\"+test_data['Area Code']+\"_\"+test_data['Sourcing Channel']+\"_\"+test_data['Product Size']+\"_\"+test_data['Product Type']\n",
    "test_feature_category = test_data[\"feature_category\"].unique().tolist()\n",
    "test_data[\"Date\"] = pd.to_datetime(test_data[\"Month of Sourcing\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f97650f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductType</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Sourcing Channel</th>\n",
       "      <th>Product Size</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Month of Sourcing</th>\n",
       "      <th>Sourcing Cost</th>\n",
       "      <th>feature_category</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NTM3</td>\n",
       "      <td>X1</td>\n",
       "      <td>A28</td>\n",
       "      <td>WHOLESALE</td>\n",
       "      <td>Large</td>\n",
       "      <td>Powder</td>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>10.158</td>\n",
       "      <td>NTM3_X1_A28_WHOLESALE_Large_Powder</td>\n",
       "      <td>2021-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NTM2</td>\n",
       "      <td>X1</td>\n",
       "      <td>A9</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>Large</td>\n",
       "      <td>Powder</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>134.281</td>\n",
       "      <td>NTM2_X1_A9_DIRECT_Large_Powder</td>\n",
       "      <td>2020-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NTM3</td>\n",
       "      <td>X2</td>\n",
       "      <td>A20</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>Large</td>\n",
       "      <td>Powder</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>12.456</td>\n",
       "      <td>NTM3_X2_A20_DIRECT_Large_Powder</td>\n",
       "      <td>2020-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NTM3</td>\n",
       "      <td>X1</td>\n",
       "      <td>A18</td>\n",
       "      <td>WHOLESALE</td>\n",
       "      <td>Small</td>\n",
       "      <td>Powder</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>107.220</td>\n",
       "      <td>NTM3_X1_A18_WHOLESALE_Small_Powder</td>\n",
       "      <td>2021-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NTM2</td>\n",
       "      <td>X1</td>\n",
       "      <td>A28</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>Large</td>\n",
       "      <td>Liquid</td>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>197.763</td>\n",
       "      <td>NTM2_X1_A28_DIRECT_Large_Liquid</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ProductType Manufacturer Area Code Sourcing Channel Product Size  \\\n",
       "0        NTM3           X1       A28        WHOLESALE        Large   \n",
       "1        NTM2           X1        A9           DIRECT        Large   \n",
       "2        NTM3           X2       A20           DIRECT        Large   \n",
       "3        NTM3           X1       A18        WHOLESALE        Small   \n",
       "4        NTM2           X1       A28           DIRECT        Large   \n",
       "\n",
       "  Product Type Month of Sourcing  Sourcing Cost  \\\n",
       "0       Powder        2021-05-01         10.158   \n",
       "1       Powder        2020-10-01        134.281   \n",
       "2       Powder        2020-12-01         12.456   \n",
       "3       Powder        2021-02-01        107.220   \n",
       "4       Liquid        2020-11-01        197.763   \n",
       "\n",
       "                     feature_category       Date  \n",
       "0  NTM3_X1_A28_WHOLESALE_Large_Powder 2021-05-01  \n",
       "1      NTM2_X1_A9_DIRECT_Large_Powder 2020-10-01  \n",
       "2     NTM3_X2_A20_DIRECT_Large_Powder 2020-12-01  \n",
       "3  NTM3_X1_A18_WHOLESALE_Small_Powder 2021-02-01  \n",
       "4     NTM2_X1_A28_DIRECT_Large_Liquid 2020-11-01  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b821d1",
   "metadata": {},
   "source": [
    "## Preprocessing Steps \n",
    "- For a specific key (label) I have considered mean value of sourcing cost if it has more than 1 sourcing cost for single date.\n",
    "- Identified missing values and imputed them using pycaret's imputation method. - \"Drift\"\n",
    "- Identified outlier using Qartiles (Q1,Q3,IQR) and outliers are treated accordingly.\n",
    "## Modelling Steps\n",
    "- Considered last 2 data points of training data as test data for model comparison.\n",
    "- Considered time series models and trained on (n-2) records.\n",
    "- Considered top 2 models based on MAPE metric.\n",
    "- Combined top 2 models using blender functionality and have applied tuning functionality from pycaret library and again re trained on entire training data set.\n",
    "- Forecasted the june month data using the final model for each of the label\n",
    "## Preparing the dictionary with labels as keys\n",
    "### Each Key will have information mentioned below\n",
    "- missing_values -- (whether the training data of each label has any missing date between its minimum and maximum existing dates)\n",
    "- data_statistics -- (statistical distribution metrics of training data for each label)\n",
    "- train_data -- (contains training data after applying preprocessing steps - missing value treatment, outlier treatment also contains forecasted values for all the existing points using final model - yhat and if any data point is outlier treated)\n",
    "- top_2_models -- (contains information about the selected top - 2 models based on MAPE metric)\n",
    "- model_error_metrics -- (contains information of all the metric scores for all the models trained on training data)\n",
    "- best_model_error_metrics -- (contains information of residual and error metric scores for the best model - top - 1 model )\n",
    "- final_model -- (final model - which is first ensembled using top 2 models, fine tuned and at last retrained on entire training data)\n",
    "- test_data -- (contains actual June data along with forecasted value using final model - yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "442ac1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "#### Hierarchy of label information ####\n",
    "\n",
    "label_information \n",
    "    label\n",
    "        missing_values,\n",
    "        data_statistics\n",
    "        train_data\n",
    "        top_2_models\n",
    "        model_error_metrics\n",
    "        best_model_error_metrics\n",
    "        final_model\n",
    "        test_data\n",
    "\n",
    "'''\n",
    "label_information = {}\n",
    "anomaly_feature_categories = []\n",
    "selected_models = ['naive','arima','polytrend','auto_arima','exp_smooth','ets','tbats','prophet']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c7568b",
   "metadata": {},
   "source": [
    "## Preprocessing, Outlier Treatment, Missing value treatment, Training on time series models, Ensembling Top 2 models, Forecasting for JUNE month (test data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b944cd82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in range(0,len(train_feature_category)):\n",
    "    i = train_feature_category[k]\n",
    "    print (\"Started ==> \",i)\n",
    "    label_information[i] = {}\n",
    "    train_df = pd.DataFrame(train_data[train_data.feature_category==i].groupby(\"Date\").apply(lambda x: round(x[\"Sourcing Cost\"].mean(),2)),columns=[\"sourcing_cost\"])\n",
    "    train_df[\"Date\"] = train_df.index\n",
    "    \n",
    "    min_date = train_df.Date.min()\n",
    "    max_date = train_df.Date.max()\n",
    "    date_df = pd.DataFrame(pd.date_range(start=min_date,end=max_date,freq=\"MS\"),columns=[\"Date\"])\n",
    "    if train_df.shape[0] < date_df.shape[0]:\n",
    "        label_information[i][\"missing_values\"] = [\"yes\",date_df.shape[0] - train_df.shape[0]]\n",
    "        temp_df_1 = pd.merge(train_df.reset_index(drop=True),date_df,on=\"Date\",how=\"outer\").sort_values(\"Date\")\n",
    "        temp_df_1.index = temp_df_1.Date\n",
    "        train_df = temp_df_1\n",
    "    else:\n",
    "        label_information[i][\"missing_values\"] = [\"no\",0]\n",
    "        \n",
    "\n",
    "    train_df[\"month_name\"] = train_df.Date.apply(lambda x: x.month_name())\n",
    "    train_df[\"month_num\"] = train_df.Date.apply(lambda x: x.month)\n",
    "    \n",
    "    Q1 = train_df.sourcing_cost.quantile(0.25)\n",
    "    Q3 = train_df.sourcing_cost.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - 1.5*IQR\n",
    "    upper_limit = Q3 + 1.5*IQR\n",
    "    train_df[\"Anomaly\"] = 0\n",
    "    train_df.loc[(train_df.sourcing_cost > upper_limit),\"Anomaly\"] = 1\n",
    "    train_df.loc[(train_df.sourcing_cost < lower_limit),\"Anomaly\"] = 1\n",
    "    \n",
    "    train_df[\"source_outlier_treated\"] = np.where(\n",
    "                                                train_df[\"sourcing_cost\"]>upper_limit,\n",
    "                                                upper_limit,\n",
    "                                                np.where(train_df[\"sourcing_cost\"] < lower_limit, \n",
    "                                                lower_limit,\n",
    "                                                train_df[\"sourcing_cost\"])\n",
    "                                                )\n",
    "    if train_df[train_df.Anomaly==1].shape[0] > 0:\n",
    "        anomaly_feature_categories.append(i)\n",
    "        #print (i,\" '''Has Anomalies'''' \")\n",
    "    \n",
    "    \n",
    "    label_information[i][\"train_data\"] = train_df\n",
    "    \n",
    "    temp_df = train_df.copy()\n",
    "    \n",
    "    ## Data Statistics\n",
    "    try:\n",
    "        df_setup = setup(data = temp_df[[\"source_outlier_treated\",\"Date\"]],index=\"Date\", target = 'source_outlier_treated',fold=2,fh=3,numeric_imputation_target=\"drift\")\n",
    "    except Exception as e:\n",
    "        print (str(e))\n",
    "        df_setup = setup(data = temp_df[[\"source_outlier_treated\",\"Date\"]],index=\"Date\", target = 'source_outlier_treated',fold=2,fh=2,numeric_imputation_target=\"drift\")\n",
    "        \n",
    "    df_stats = check_stats()\n",
    "    df_stats\n",
    "    label_information[i][\"data_statistics\"] = df_stats\n",
    "    \n",
    "    # Model Training, top 2 models (MAPE based)\n",
    "    df_best = compare_models(include=selected_models,sort=\"MAPE\",n_select=2)\n",
    "    df_models_metrics = pull()\n",
    "    label_information[i][\"top_2_models\"] = df_best\n",
    "    \n",
    "    req_metrics = [\"Model\",\"MAE\",\"RMSE\",\"MAPE\"]\n",
    "    df_models_metrics_req = df_models_metrics[req_metrics]\n",
    "    label_information[i][\"model_error_metrics\"] = df_models_metrics_req\n",
    "    \n",
    "    \n",
    "    best_model_residuals_metrics = check_stats(estimator=df_best[0])\n",
    "    best_model_residuals_metrics\n",
    "    label_information[i][\"best_model_error_metrics\"] = best_model_residuals_metrics\n",
    "\n",
    "    blender = blend_models(df_best)\n",
    "    tuned_blender = tune_model(blender)\n",
    "    final_model = finalize_model(tuned_blender)\n",
    "    label_information[i][\"final_model\"] = final_model\n",
    "\n",
    "    temp_t = plot_model(estimator=final_model,return_fig=False,return_data=True,plot=\"insample\")\n",
    "    y_hat = temp_t[\"overlay_data\"].reset_index(drop=True)\n",
    "    temp_df[\"y_hat\"] = y_hat[\"EnsembleForecaster\"].tolist()\n",
    "    label_information[i][\"train_data\"] = temp_df\n",
    "    \n",
    "    \n",
    "    temp_f = plot_model(final_model,plot=\"forecast\",data_kwargs={\"fh\":3},return_data=True)\n",
    "    \n",
    "    \n",
    "    test_df = pd.DataFrame(test_data[test_data.feature_category==i].groupby(\"Date\").apply(lambda x: round(x[\"Sourcing Cost\"].sum(),2)),columns=[\"sourcing_cost\"])\n",
    "    test_df[\"Date\"] = test_df.index\n",
    "    test_df[\"month_name\"] = test_df.Date.apply(lambda x: x.month_name())\n",
    "    test_df[\"month_num\"] = test_df.Date.apply(lambda x: x.month)\n",
    "    \n",
    "    y_hat_future = temp_f[\"overlay_data\"].reset_index(drop=True)\n",
    "    test_df[\"y_hat\"] = y_hat_future[\"EnsembleForecaster\"].tolist()[:1]\n",
    "    \n",
    "    label_information[i][\"test_data\"] = test_df\n",
    "    print (\"Ended ==> \",i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d18b05",
   "metadata": {},
   "source": [
    "## Storing the label information as pickel file in local system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8997cd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('label_information_mean.pickle', 'wb') as handle:\n",
    "    pickle.dump(label_information, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    \n",
    "\n",
    "'''\n",
    "with open('label_information_mean.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2624653c",
   "metadata": {},
   "source": [
    "## Test data with forecasted value using final model for label - saving as csv into local system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "85ccae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_forecasted_data = pd.concat([label_information[i][\"test_data\"].reset_index(drop=True) for i in train_feature_category],axis=0)\n",
    "test_forecasted_data[\"label\"] = train_feature_category\n",
    "test_forecasted_data.to_csv(\"test_forecasted_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2e9f7c",
   "metadata": {},
   "source": [
    "## Train data with forecasted value using final model for label - saving as csv into local system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8ab5730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_forecasted_data = [label_information[i][\"train_data\"].reset_index(drop=True) for i in train_feature_category]\n",
    "label_train = []\n",
    "for num,i in enumerate(train_feature_category):\n",
    "    label_train = label_train + [i]*train_forecasted_data[num].shape[0]\n",
    "\n",
    "train_forecasted_data = pd.concat(train_forecasted_data,axis=0)\n",
    "train_forecasted_data[\"label\"] = label_train\n",
    "train_forecasted_data.to_csv(\"train_forecasted_data.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
